---
title: "ML_PROJECT"
author: "AYUSH BHARGAVA"
date: "November 28, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Goal
We will analyze the exercise data collected on six people using wearable devices such as awbone Up, Nike FuelBand, and Fitbit. We are particularly insterested in finding out how well they perform barball lifts. We will build some predictive models to predict this characteristic on new datasets and try to find the best model.

##Data
The training data for this project are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>
The test data are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>

##Strategy
-This is a classification problem where we have to build predictive models for predicting outcome of a factor variable "classe"" having 5 levels
-As this is a classification problem we will use accuracy as a metric to check errors in our predictions
-Random Forest and classification trees are best suited for classification problems so we will work with these algorithms and find which performs best

##Loading libraries,data and doing preliminary analysis
```{r}
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(randomForest)))
suppressWarnings(suppressMessages(library(rpart)))
suppressWarnings(suppressMessages(library(rpart.plot)))
# setting the overall seed for reproduceability
set.seed(1234)
#loading training data set
training <- read.csv("C:/Users/Ayush Bhargava/Desktop/Practical ml project/pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
#loading testing data set
testing <- read.csv("C:/Users/Ayush Bhargava/Desktop/Practical ml project/pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
#looking at the training data
str(training)
```
##Analysis summary and Preprocessing the data
-There are many columns which have mostly "na" values thus we will get rid of them
```{r}
training<-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]
```
-There are many columns such as participant name etc(column no. 1 to 7) which are not usefull for this project thus we will get rid of these columns as well
```{r}
training<-training[,-c(1:7)]
testing <-testing[,-c(1:7)]
dim(training)
dim(testing)
```
-We have enough observations in training data set to further divide training data in to subtraining(75%) and subtesting(25%) datasets for cross validation purposes
```{r}
subsamples <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
subTraining <- training[subsamples, ] 
subTesting <- training[-subsamples, ]
dim(subTraining)
dim(subTesting)
```
## Prediction Models
## Classification tree
```{r}
model1 <- rpart(classe ~ ., data=subTraining, method="class")

# Predictions:
prediction1 <- predict(model1, subTesting, type = "class")

# The Decision Tree
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)

# Test results on subTesting data set:
confusionMatrix(prediction1, subTesting$classe)
```
From the above confusion matrix result it is clear that classification tree did not perform well and was able to predict on our subTesting data with 74% accuray.
Lets bulid our second model 

##Random Forest
```{r}
model2 <- randomForest(classe ~. , data=subTraining, method="class")

# Predicting:
prediction2 <- predict(model2, subTesting, type = "class")

# Test results on subTesting data set:
confusionMatrix(prediction2, subTesting$classe)
```
Random forest is able to predict with 99.5% accuracy and thus outperfomred classification tree and as it is able to predict quite accurately on the subTesting dataset we will move ahead and predict on our actual testing data with model2
```{r}
# predict outcome levels on the actual Testing data set using Random Forest algorithm
predictfinal <- predict(model2, testing, type="class")
predictfinal
```







